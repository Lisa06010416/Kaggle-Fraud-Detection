{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read uid\n",
    "uids = pd.read_csv(\"data/uids_full_v6.csv\",usecols=['TransactionID','uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "X_test = pd.read_csv(\"data/X_test.csv\")\n",
    "X_train = pd.read_csv(\"data/X_train.csv\")\n",
    "Y_train = pd.read_csv(\"data/Y_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns\n",
    "for c in cols:\n",
    "    if c not in ['TransactionID','uid']:\n",
    "        X_test[c] = (X_test[c] - X_train[c].min())/(X_train[c].max()- X_train[c].min())\n",
    "for c in cols:\n",
    "    if c not in ['TransactionID','uid']:\n",
    "        X_train[c] = (X_train[c] - X_train[c].min())/(X_train[c].max()- X_train[c].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make RNN training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 3., 3., 4., 6.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge X Y\n",
    "merge = pd.merge(X_train,Y_train, on='TransactionID')\n",
    "# 把同一個使用者的資料分為一組\n",
    "merge_group = merge.groupby(\"uid\")\n",
    "# 看使用者交易總數的分布\n",
    "np.percentile(merge_group.size().values, [25, 50, 75, 80, 85, 90])\n",
    "# RNN time step => 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_Num = len(merge.columns)-3\n",
    "X_Train_Seq = []\n",
    "Y_Train_Seq = []\n",
    "p = [-99 for i in range(F_Num)]\n",
    "for gn, data in merge_group:\n",
    "    data_len = len(data)\n",
    "    # y \n",
    "    data_y = data.isFraud.values\n",
    "    # x\n",
    "    data = data.drop(['uid','isFraud','TransactionID'], axis=1)\n",
    "    data_value = data.values\n",
    "    \n",
    "    # 把交易紀錄分為三個一組\n",
    "    if data_len == 3:\n",
    "        X_Train_Seq.append(data_value)\n",
    "        Y_Train_Seq.append(data_y)\n",
    "    elif data_len <= 3:\n",
    "        padding_num = 3-data_len\n",
    "        padding = np.array([ p for i in range(padding_num)])\n",
    "        X_Train_Seq.append(np.append(data_value,padding, axis=0))\n",
    "        Y_Train_Seq.append(np.append(data_y,[0 for i in range(padding_num)]))\n",
    "    else:\n",
    "        for i in range(data_len//3):\n",
    "            X_Train_Seq.append(data_value[i*3:i*3+3])\n",
    "            Y_Train_Seq.append(data_y[i*3:i*3+3])\n",
    "        if data_len%3>0:\n",
    "            padding_num = 3-data_len%3\n",
    "            padding = np.array([ p for i in range(padding_num)])\n",
    "            X_Train_Seq.append(np.append(data_value[-(data_len%3):], padding, axis=0))\n",
    "            Y_Train_Seq.append(np.append(data_y[-(data_len%3):], [0 for i in range(padding_num)], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group = X_test.groupby(\"uid\")\n",
    "X_Test_Seq = []\n",
    "TranID_Seq = []\n",
    "for gn, data in test_group:\n",
    "    data_len = len(data)\n",
    "    # x\n",
    "    TranID_Seq.extend(list(data.TransactionID.values))\n",
    "    data = data.drop(['uid','TransactionID'], axis=1)\n",
    "    data_value = data.values\n",
    "    # 把交易紀錄分為三個一組\n",
    "    if data_len == 3:\n",
    "        X_Test_Seq.append(data_value)\n",
    "    elif data_len <= 3:\n",
    "        padding_num = 3-data_len\n",
    "        TranID_Seq.extend([-1 for i in range(padding_num)])\n",
    "        padding = np.array([ p for i in range(padding_num)])\n",
    "        X_Test_Seq.append(np.append(data_value,padding, axis=0))\n",
    "    else:\n",
    "        for i in range(data_len//3):\n",
    "            X_Test_Seq.append(data_value[i*3:i*3+3])\n",
    "        if data_len%3>0:\n",
    "            padding_num = 3-data_len%3\n",
    "            TranID_Seq.extend([-1 for i in range(padding_num)])\n",
    "            padding = np.array([ p for i in range(padding_num)])\n",
    "            X_Test_Seq.append(np.append(data_value[-(data_len%3):], padding, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "fileObject = open(\"data/X_Train_Seq\", 'wb')\n",
    "pkl.dump(X_Train_Seq, fileObject)\n",
    "fileObject.close()\n",
    "\n",
    "fileObject = open(\"data/Y_Train_Seq\", 'wb')\n",
    "pkl.dump(Y_Train_Seq, fileObject)\n",
    "fileObject.close()\n",
    "\n",
    "fileObject = open(\"data/X_Test_Seq\", 'wb')\n",
    "pkl.dump(X_Test_Seq, fileObject)\n",
    "fileObject.close()\n",
    "\n",
    "fileObject = open(\"data/TranID_Seq\", 'wb')\n",
    "pkl.dump(TranID_Seq, fileObject)\n",
    "fileObject.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
