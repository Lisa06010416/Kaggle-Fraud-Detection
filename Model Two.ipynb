{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadfile = open('data/X_Train_Seq', 'rb')\n",
    "X_Train_Seq = pkl.load(loadfile)\n",
    "loadfile.close()\n",
    "\n",
    "loadfile = open('data/X_Test_Seq', 'rb')\n",
    "X_Test_Seq = pkl.load(loadfile)\n",
    "loadfile.close()\n",
    "\n",
    "loadfile = open('data/Y_Train_Seq', 'rb')\n",
    "Y_Train_Seq = pkl.load(loadfile)\n",
    "loadfile.close()\n",
    "\n",
    "loadfile = open('data/TranID_Seq', 'rb')\n",
    "TranID_Seq = pkl.load(loadfile)\n",
    "loadfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import Sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, LSTM, Masking, Dropout, BatchNormalization, Input, Lambda\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = len(X_Train_Seq[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_mse(y_true, y_pred):\n",
    "    fraud = tf.ones_like(y_pred) - tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    normal = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "    return 10*K.mean(fraud*fraud) + K.mean(normal*normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(vecs):\n",
    "    all_h, c = vecs\n",
    "    c = tf.expand_dims(c,1)\n",
    "    weight = activations.softmax(K.sum(all_h*c,axis=-1))\n",
    "    weight = tf.expand_dims(weight,2)\n",
    "    vector = K.sum(weight*all_h,axis=1,keepdims=True)\n",
    "    return tf.tile(vector,[1,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 263)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 3, 263)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 3, 263)       0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 3, 50), (Non 62800       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 3, 50)        0           lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 3, 50)        0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3, 32)        1632        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 3, 32)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3, 1)         33          dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 64,465\n",
      "Trainable params: 64,465\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (3,feature_num)\n",
    "inputs  = Input(shape = input_shape)\n",
    "x = Masking(mask_value=-99, input_shape=(3, feature_num))(inputs)\n",
    "x = Dropout(0.2)(x)\n",
    "all_h, _, c = LSTM(50, return_sequences=True, return_state=True)(x)\n",
    "x = Lambda(attention)([all_h, c])\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions  = Dense(1, activation='relu')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss=modify_mse, metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 246484 samples, validate on 61622 samples\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "246484/246484 [==============================] - 100s 404us/step - loss: 0.1379 - acc: 0.9522 - val_loss: 0.1441 - val_acc: 0.9002\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14406, saving model to best2.hdf5\n",
      "Epoch 2/1000\n",
      "246484/246484 [==============================] - 93s 377us/step - loss: 0.1280 - acc: 0.9522 - val_loss: 0.1331 - val_acc: 0.9033\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14406 to 0.13315, saving model to best2.hdf5\n",
      "Epoch 3/1000\n",
      "246484/246484 [==============================] - 93s 378us/step - loss: 0.1227 - acc: 0.9536 - val_loss: 0.1266 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13315 to 0.12656, saving model to best2.hdf5\n",
      "Epoch 4/1000\n",
      "246484/246484 [==============================] - 93s 378us/step - loss: 0.1199 - acc: 0.9537 - val_loss: 0.1272 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12656\n",
      "Epoch 5/1000\n",
      "246484/246484 [==============================] - 94s 380us/step - loss: 0.1167 - acc: 0.9545 - val_loss: 0.1265 - val_acc: 0.9307\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12656 to 0.12646, saving model to best2.hdf5\n",
      "Epoch 6/1000\n",
      "246484/246484 [==============================] - 93s 379us/step - loss: 0.1155 - acc: 0.9549 - val_loss: 0.1259 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12646 to 0.12585, saving model to best2.hdf5\n",
      "Epoch 7/1000\n",
      "246484/246484 [==============================] - 94s 382us/step - loss: 0.1137 - acc: 0.9553 - val_loss: 0.1240 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.12585 to 0.12402, saving model to best2.hdf5\n",
      "Epoch 8/1000\n",
      "246484/246484 [==============================] - 94s 380us/step - loss: 0.1125 - acc: 0.9552 - val_loss: 0.1282 - val_acc: 0.9534\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12402\n",
      "Epoch 9/1000\n",
      "246484/246484 [==============================] - 94s 381us/step - loss: 0.1109 - acc: 0.9559 - val_loss: 0.1319 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12402\n",
      "Epoch 10/1000\n",
      "246484/246484 [==============================] - 95s 384us/step - loss: 0.1100 - acc: 0.9556 - val_loss: 0.1286 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12402\n",
      "Epoch 11/1000\n",
      "246484/246484 [==============================] - 95s 386us/step - loss: 0.1094 - acc: 0.9557 - val_loss: 0.1291 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.12402\n",
      "Epoch 12/1000\n",
      "246484/246484 [==============================] - 96s 390us/step - loss: 0.1081 - acc: 0.9564 - val_loss: 0.1305 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.12402\n",
      "Epoch 13/1000\n",
      "246484/246484 [==============================] - 96s 389us/step - loss: 0.1073 - acc: 0.9557 - val_loss: 0.1322 - val_acc: 0.9617\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.12402\n",
      "Epoch 14/1000\n",
      "246484/246484 [==============================] - 96s 389us/step - loss: 0.1067 - acc: 0.9558 - val_loss: 0.1288 - val_acc: 0.9394\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.12402\n",
      "Epoch 15/1000\n",
      "246484/246484 [==============================] - 97s 393us/step - loss: 0.1061 - acc: 0.9562 - val_loss: 0.1267 - val_acc: 0.9359\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.12402\n",
      "Epoch 16/1000\n",
      "246484/246484 [==============================] - 96s 389us/step - loss: 0.1048 - acc: 0.9561 - val_loss: 0.1287 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.12402\n",
      "Epoch 17/1000\n",
      "246484/246484 [==============================] - 97s 394us/step - loss: 0.1041 - acc: 0.9570 - val_loss: 0.1272 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.12402\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3633f5f5c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weights_filepath = \"best2.hdf5\"\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "model.fit(np.array(X_Train_Seq), np.array(Y_Train_Seq).reshape((-1,3,1)), validation_split=0.2, epochs=1000, batch_size=128, callbacks=[callback,saveBestModel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subFile(filename,threshold):\n",
    "    predict = model.predict(np.array(X_Test_Seq)) > threshold\n",
    "    index_TranID = 0\n",
    "    answer = []\n",
    "    for seqIndex,seq in enumerate(predict) :\n",
    "        for tranIndex, tran in enumerate(seq):\n",
    "            if TranID_Seq[index_TranID]!=-1:\n",
    "                answer.append([int(TranID_Seq[index_TranID]),1 if tran else 0])\n",
    "            index_TranID+=1\n",
    "    answer = np.array(answer)\n",
    "    a = {'TransactionID':answer[:,0],\n",
    "          'isFraud':answer[:,1]}\n",
    "    ans = pd.DataFrame(a)\n",
    "    sample = pd.read_csv(\"data/IEEE/sample_submission.csv\")\n",
    "    sub = pd.merge(sample, ans, how=\"left\", on=\"TransactionID\")\n",
    "    del sub['isFraud_x']\n",
    "    sub = sub.rename(columns={'isFraud_y':'isFraud'})\n",
    "    sub.to_csv('submission/sub2_'+filename+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ['.1','.2','.3','.4','.5','.6']:\n",
    "    subFile(t,float(t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
