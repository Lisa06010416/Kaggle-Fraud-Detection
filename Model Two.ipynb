{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadfile = open('data/X_Train_Seq', 'rb')\n",
    "X_Train_Seq = pkl.load(loadfile)\n",
    "loadfile.close()\n",
    "\n",
    "loadfile = open('data/X_Test_Seq', 'rb')\n",
    "X_Test_Seq = pkl.load(loadfile)\n",
    "loadfile.close()\n",
    "\n",
    "loadfile = open('data/Y_Train_Seq', 'rb')\n",
    "Y_Train_Seq = pkl.load(loadfile)\n",
    "loadfile.close()\n",
    "\n",
    "loadfile = open('data/TranID_Seq', 'rb')\n",
    "TranID_Seq = pkl.load(loadfile)\n",
    "loadfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, LSTM, Masking, Dropout, BatchNormalization, Input, Lambda\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = len(X_Train_Seq[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_mse(y_true, y_pred):\n",
    "    fraud = tf.ones_like(y_pred) - tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    normal = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "    return 10*K.mean(fraud*fraud) + K.mean(normal*normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(vecs):\n",
    "    all_h, c = vecs\n",
    "    c = tf.expand_dims(c,1)\n",
    "    weight = activations.softmax(K.sum(all_h*c,axis=-1))\n",
    "    weight = tf.expand_dims(weight,2)\n",
    "    vector = K.sum(weight*all_h,axis=1,keepdims=True)\n",
    "    return tf.tile(vector,[1,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (3,feature_num)\n",
    "inputs  = Input(shape = input_shape)\n",
    "x = Masking(mask_value=-99, input_shape=(3, feature_num))(inputs)\n",
    "x = Dropout(0.2)(x)\n",
    "all_h, _, c = LSTM(20, return_sequences=True, return_state=True)(x)\n",
    "x = Lambda(attention)([all_h, c])\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions  = Dense(1, activation='relu')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss=modify_mse, metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_filepath = \"best.hdf5\"\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "model.fit(np.array(X_Train_Seq), np.array(Y_Train_Seq).reshape((-1,3,1)), validation_split=0.2, epochs=1000, batch_size=128, callbacks=[callback,saveBestModel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subFile(filename,threshold):\n",
    "    predict = model.predict(np.array(X_Test_Seq)) > threshold\n",
    "    index_TranID = 0\n",
    "    answer = []\n",
    "    for seqIndex,seq in enumerate(predict) :\n",
    "        for tranIndex, tran in enumerate(seq):\n",
    "            if TranID_Seq[index_TranID]!=-1:\n",
    "                answer.append([int(TranID_Seq[index_TranID]),1 if tran else 0])\n",
    "            index_TranID+=1\n",
    "    answer = np.array(answer)\n",
    "    a = {'TransactionID':answer[:,0],\n",
    "          'isFraud':answer[:,1]}\n",
    "    ans = pd.DataFrame(a)\n",
    "    sample = pd.read_csv(\"data/IEEE/sample_submission.csv\")\n",
    "    sub = pd.merge(sample, ans, how=\"left\", on=\"TransactionID\")\n",
    "    del sub['isFraud_x']\n",
    "    sub = sub.rename(columns={'isFraud_y':'isFraud'})\n",
    "    sub.to_csv('sum_'+filename+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ['.1','.2','.3','.4','.5','.6']:\n",
    "    subFile(t,float(t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
