{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadfile = open('data/X_Train_Seq', 'rb')\n",
    "X_Train_Seq = pkl.load(loadfile)\n",
    "loadfile.close()\n",
    "\n",
    "loadfile = open('data/X_Test_Seq', 'rb')\n",
    "X_Test_Seq = pkl.load(loadfile)\n",
    "loadfile.close()\n",
    "\n",
    "loadfile = open('data/Y_Train_Seq', 'rb')\n",
    "Y_Train_Seq = pkl.load(loadfile)\n",
    "loadfile.close()\n",
    "\n",
    "loadfile = open('data/TranID_Seq', 'rb')\n",
    "TranID_Seq = pkl.load(loadfile)\n",
    "loadfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Masking, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = len(X_Train_Seq[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_mse(y_true, y_pred):\n",
    "    fraud = tf.ones_like(y_pred) - tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    normal = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "    return 10*K.mean(fraud*fraud) + K.mean(normal*normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, 3, 263)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 263)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 3, 50)             62800     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 50)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3, 32)             1632      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3, 1)              33        \n",
      "=================================================================\n",
      "Total params: 64,465\n",
      "Trainable params: 64,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value=-99, input_shape=(3, feature_num)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss=modify_mse, metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 246484 samples, validate on 61622 samples\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/linlisa1017/.conda/envs/lisa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "246484/246484 [==============================] - 59s 240us/step - loss: 0.1426 - acc: 0.9396 - val_loss: 0.1371 - val_acc: 0.9561\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13712, saving model to best1.hdf5\n",
      "Epoch 2/1000\n",
      "246484/246484 [==============================] - 82s 334us/step - loss: 0.1287 - acc: 0.9411 - val_loss: 0.1321 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13712 to 0.13214, saving model to best1.hdf5\n",
      "Epoch 3/1000\n",
      "246484/246484 [==============================] - 87s 352us/step - loss: 0.1242 - acc: 0.9414 - val_loss: 0.1282 - val_acc: 0.9466\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13214 to 0.12824, saving model to best1.hdf5\n",
      "Epoch 4/1000\n",
      "246484/246484 [==============================] - 87s 352us/step - loss: 0.1213 - acc: 0.9440 - val_loss: 0.1283 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12824\n",
      "Epoch 5/1000\n",
      "246484/246484 [==============================] - 87s 352us/step - loss: 0.1185 - acc: 0.9444 - val_loss: 0.1272 - val_acc: 0.9327\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12824 to 0.12721, saving model to best1.hdf5\n",
      "Epoch 6/1000\n",
      "246484/246484 [==============================] - 86s 351us/step - loss: 0.1171 - acc: 0.9445 - val_loss: 0.1288 - val_acc: 0.9567\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.12721\n",
      "Epoch 7/1000\n",
      "246484/246484 [==============================] - 86s 350us/step - loss: 0.1156 - acc: 0.9441 - val_loss: 0.1291 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.12721\n",
      "Epoch 8/1000\n",
      "246484/246484 [==============================] - 87s 352us/step - loss: 0.1141 - acc: 0.9462 - val_loss: 0.1278 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12721\n",
      "Epoch 9/1000\n",
      "246484/246484 [==============================] - 86s 350us/step - loss: 0.1128 - acc: 0.9460 - val_loss: 0.1283 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12721\n",
      "Epoch 10/1000\n",
      "246484/246484 [==============================] - 86s 351us/step - loss: 0.1113 - acc: 0.9461 - val_loss: 0.1301 - val_acc: 0.9349\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12721\n",
      "Epoch 11/1000\n",
      "246484/246484 [==============================] - 87s 352us/step - loss: 0.1101 - acc: 0.9474 - val_loss: 0.1283 - val_acc: 0.9558\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.12721\n",
      "Epoch 12/1000\n",
      "246484/246484 [==============================] - 86s 350us/step - loss: 0.1096 - acc: 0.9473 - val_loss: 0.1286 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.12721\n",
      "Epoch 13/1000\n",
      "246484/246484 [==============================] - 88s 356us/step - loss: 0.1086 - acc: 0.9472 - val_loss: 0.1288 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.12721\n",
      "Epoch 14/1000\n",
      "246484/246484 [==============================] - 88s 358us/step - loss: 0.1082 - acc: 0.9475 - val_loss: 0.1257 - val_acc: 0.9415\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.12721 to 0.12568, saving model to best1.hdf5\n",
      "Epoch 15/1000\n",
      "246484/246484 [==============================] - 88s 357us/step - loss: 0.1074 - acc: 0.9475 - val_loss: 0.1274 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.12568\n",
      "Epoch 16/1000\n",
      "246484/246484 [==============================] - 88s 355us/step - loss: 0.1071 - acc: 0.9478 - val_loss: 0.1258 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.12568\n",
      "Epoch 17/1000\n",
      "246484/246484 [==============================] - 89s 361us/step - loss: 0.1062 - acc: 0.9479 - val_loss: 0.1265 - val_acc: 0.9363\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.12568\n",
      "Epoch 18/1000\n",
      "246484/246484 [==============================] - 89s 359us/step - loss: 0.1056 - acc: 0.9493 - val_loss: 0.1292 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.12568\n",
      "Epoch 19/1000\n",
      "246484/246484 [==============================] - 89s 361us/step - loss: 0.1053 - acc: 0.9482 - val_loss: 0.1256 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.12568 to 0.12558, saving model to best1.hdf5\n",
      "Epoch 20/1000\n",
      "246484/246484 [==============================] - 88s 358us/step - loss: 0.1048 - acc: 0.9490 - val_loss: 0.1276 - val_acc: 0.9401\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.12558\n",
      "Epoch 21/1000\n",
      "246484/246484 [==============================] - 85s 346us/step - loss: 0.1046 - acc: 0.9485 - val_loss: 0.1278 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.12558\n",
      "Epoch 22/1000\n",
      "246484/246484 [==============================] - 86s 350us/step - loss: 0.1038 - acc: 0.9496 - val_loss: 0.1278 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.12558\n",
      "Epoch 23/1000\n",
      "246484/246484 [==============================] - 86s 349us/step - loss: 0.1030 - acc: 0.9507 - val_loss: 0.1247 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.12558 to 0.12468, saving model to best1.hdf5\n",
      "Epoch 24/1000\n",
      "246484/246484 [==============================] - 86s 349us/step - loss: 0.1026 - acc: 0.9498 - val_loss: 0.1250 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.12468\n",
      "Epoch 25/1000\n",
      "246484/246484 [==============================] - 86s 350us/step - loss: 0.1025 - acc: 0.9504 - val_loss: 0.1253 - val_acc: 0.9563\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.12468\n",
      "Epoch 26/1000\n",
      "246484/246484 [==============================] - 68s 275us/step - loss: 0.1021 - acc: 0.9493 - val_loss: 0.1274 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.12468\n",
      "Epoch 27/1000\n",
      "246484/246484 [==============================] - 53s 213us/step - loss: 0.1009 - acc: 0.9503 - val_loss: 0.1256 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.12468\n",
      "Epoch 28/1000\n",
      "246484/246484 [==============================] - 53s 214us/step - loss: 0.1014 - acc: 0.9493 - val_loss: 0.1249 - val_acc: 0.9398\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.12468\n",
      "Epoch 29/1000\n",
      "246484/246484 [==============================] - 53s 215us/step - loss: 0.1009 - acc: 0.9493 - val_loss: 0.1251 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.12468\n",
      "Epoch 30/1000\n",
      "246484/246484 [==============================] - 53s 215us/step - loss: 0.1000 - acc: 0.9496 - val_loss: 0.1284 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.12468\n",
      "Epoch 31/1000\n",
      "246484/246484 [==============================] - 53s 214us/step - loss: 0.1006 - acc: 0.9504 - val_loss: 0.1243 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.12468 to 0.12425, saving model to best1.hdf5\n",
      "Epoch 32/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246484/246484 [==============================] - 52s 213us/step - loss: 0.1001 - acc: 0.9505 - val_loss: 0.1235 - val_acc: 0.9487\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.12425 to 0.12346, saving model to best1.hdf5\n",
      "Epoch 33/1000\n",
      "246484/246484 [==============================] - 53s 215us/step - loss: 0.0998 - acc: 0.9507 - val_loss: 0.1249 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.12346\n",
      "Epoch 34/1000\n",
      "246484/246484 [==============================] - 53s 215us/step - loss: 0.0985 - acc: 0.9508 - val_loss: 0.1271 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.12346\n",
      "Epoch 35/1000\n",
      "246484/246484 [==============================] - 54s 218us/step - loss: 0.0988 - acc: 0.9507 - val_loss: 0.1242 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.12346\n",
      "Epoch 36/1000\n",
      "246484/246484 [==============================] - 53s 217us/step - loss: 0.0985 - acc: 0.9512 - val_loss: 0.1287 - val_acc: 0.9615\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.12346\n",
      "Epoch 37/1000\n",
      "246484/246484 [==============================] - 54s 217us/step - loss: 0.0979 - acc: 0.9521 - val_loss: 0.1267 - val_acc: 0.9586\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.12346\n",
      "Epoch 38/1000\n",
      "246484/246484 [==============================] - 53s 216us/step - loss: 0.0981 - acc: 0.9510 - val_loss: 0.1276 - val_acc: 0.9598\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.12346\n",
      "Epoch 39/1000\n",
      "246484/246484 [==============================] - 53s 214us/step - loss: 0.0969 - acc: 0.9511 - val_loss: 0.1273 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.12346\n",
      "Epoch 40/1000\n",
      "246484/246484 [==============================] - 54s 217us/step - loss: 0.0978 - acc: 0.9503 - val_loss: 0.1267 - val_acc: 0.9590\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.12346\n",
      "Epoch 41/1000\n",
      "246484/246484 [==============================] - 53s 216us/step - loss: 0.0972 - acc: 0.9512 - val_loss: 0.1234 - val_acc: 0.9461\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.12346 to 0.12345, saving model to best1.hdf5\n",
      "Epoch 42/1000\n",
      "246484/246484 [==============================] - 53s 215us/step - loss: 0.0968 - acc: 0.9514 - val_loss: 0.1257 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.12345\n",
      "Epoch 43/1000\n",
      "246484/246484 [==============================] - 54s 217us/step - loss: 0.0966 - acc: 0.9513 - val_loss: 0.1246 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.12345\n",
      "Epoch 44/1000\n",
      "246484/246484 [==============================] - 54s 217us/step - loss: 0.0965 - acc: 0.9519 - val_loss: 0.1263 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.12345\n",
      "Epoch 45/1000\n",
      "246484/246484 [==============================] - 54s 219us/step - loss: 0.0964 - acc: 0.9519 - val_loss: 0.1259 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.12345\n",
      "Epoch 46/1000\n",
      "246484/246484 [==============================] - 60s 242us/step - loss: 0.0960 - acc: 0.9514 - val_loss: 0.1245 - val_acc: 0.9517\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.12345\n",
      "Epoch 47/1000\n",
      "246484/246484 [==============================] - 54s 221us/step - loss: 0.0957 - acc: 0.9517 - val_loss: 0.1239 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.12345\n",
      "Epoch 48/1000\n",
      "246484/246484 [==============================] - 53s 216us/step - loss: 0.0955 - acc: 0.9511 - val_loss: 0.1247 - val_acc: 0.9527\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.12345\n",
      "Epoch 49/1000\n",
      "246484/246484 [==============================] - 53s 214us/step - loss: 0.0948 - acc: 0.9519 - val_loss: 0.1263 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.12345\n",
      "Epoch 50/1000\n",
      "246484/246484 [==============================] - 53s 216us/step - loss: 0.0946 - acc: 0.9516 - val_loss: 0.1279 - val_acc: 0.9331\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.12345\n",
      "Epoch 51/1000\n",
      "246484/246484 [==============================] - 53s 216us/step - loss: 0.0950 - acc: 0.9511 - val_loss: 0.1271 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.12345\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea35b9b320>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_weights_filepath = \"best1.hdf5\"\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "model.fit(np.array(X_Train_Seq), np.array(Y_Train_Seq).reshape((-1,3,1)), validation_split=0.2, epochs=1000, batch_size=128, callbacks=[callback,saveBestModel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subFile(filename,threshold):\n",
    "    predict = model.predict(np.array(X_Test_Seq)) > threshold\n",
    "    index_TranID = 0\n",
    "    answer = []\n",
    "    for seqIndex,seq in enumerate(predict) :\n",
    "        for tranIndex, tran in enumerate(seq):\n",
    "            if TranID_Seq[index_TranID]!=-1:\n",
    "                answer.append([int(TranID_Seq[index_TranID]),1 if tran else 0])\n",
    "            index_TranID+=1\n",
    "    answer = np.array(answer)\n",
    "    a = {'TransactionID':answer[:,0],\n",
    "          'isFraud':answer[:,1]}\n",
    "    ans = pd.DataFrame(a)\n",
    "    sample = pd.read_csv(\"data/IEEE/sample_submission.csv\")\n",
    "    sub = pd.merge(sample, ans, how=\"left\", on=\"TransactionID\")\n",
    "    del sub['isFraud_x']\n",
    "    sub = sub.rename(columns={'isFraud_y':'isFraud'})\n",
    "    sub.to_csv('submission/sub1_'+filename+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ['.1','.2','.3','.4','.5','.6']:\n",
    "    subFile(t,float(t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
